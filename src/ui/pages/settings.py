"""
Settings Page - Analizador de Documentos Legales

P√°gina de configuraci√≥n para ajustar par√°metros del sistema:
- Modelo LLM (Ollama)
- Temperatura
- Idioma OCR
- Chunking

Author: Analizador de Documentos Legales Team
Date: 2026-02-18
"""

import streamlit as st
from typing import Dict, Any

from src.utils.config_loader import get_config, save_user_overrides, reload_config


# Opciones de modelos disponibles
AVAILABLE_MODELS = [
    ("llama3.2:3b", "Llama 3.2 (3B) - Recomendado", "Balance entre calidad y velocidad"),
    ("phi3:mini", "Phi-3 Mini - Ligero", "R√°pido, menor precisi√≥n (2GB RAM)"),
    ("mistral:7b", "Mistral 7B - Preciso", "Mayor calidad, requiere m√°s recursos (8GB RAM)"),
]

# Opciones de idiomas OCR
OCR_LANGUAGES = [
    ("spa", "Espa√±ol"),
    ("spa+eng", "Espa√±ol + Ingl√©s"),
    ("eng", "Ingl√©s"),
]


def render_settings_page():
    """
    Renderiza p√°gina de configuraci√≥n completa con opciones del sistema

    Las configuraciones se guardan en config/user_overrides.yaml
    """
    st.title("‚öôÔ∏è Configuraci√≥n")

    st.markdown("""
    Personaliza el comportamiento del sistema. Los cambios se aplicar√°n al pr√≥ximo an√°lisis.
    """)

    # Cargar configuraci√≥n actual
    config = get_config()

    # Contenedor principal con tabs
    tab1, tab2, tab3 = st.tabs(["ü§ñ Modelo IA", "üîç OCR", "‚ö° Avanzado"])

    # Tab 1: Configuraci√≥n de Modelo IA
    with tab1:
        st.markdown("### Modelo de Lenguaje (Ollama)")

        st.info(
            "üí° **Nota:** Debes descargar el modelo con `ollama pull <modelo>` antes de usarlo."
        )

        # Selector de modelo
        current_model = config.ollama.model
        model_index = next(
            (i for i, (m, _, _) in enumerate(AVAILABLE_MODELS) if m == current_model),
            0
        )

        selected_model = st.selectbox(
            "Modelo",
            options=range(len(AVAILABLE_MODELS)),
            format_func=lambda i: AVAILABLE_MODELS[i][1],
            index=model_index,
            help="Modelo de IA para analizar documentos"
        )

        model_name, model_label, model_desc = AVAILABLE_MODELS[selected_model]

        st.caption(f"üìã {model_desc}")

        # Mostrar detalles del modelo seleccionado
        col1, col2 = st.columns(2)

        with col1:
            st.metric("Modelo", model_name)

        with col2:
            ram_required = {
                "llama3.2:3b": "4 GB",
                "phi3:mini": "2 GB",
                "mistral:7b": "8 GB"
            }.get(model_name, "Desconocido")
            st.metric("RAM Requerida", ram_required)

        st.markdown("---")

        # Temperatura
        st.markdown("### Temperatura")

        st.markdown("""
        Controla la aleatoriedad de las respuestas:
        - **0.1-0.2**: Determinista, respuestas consistentes (recomendado)
        - **0.3-0.5**: Mayor variabilidad, √∫til para experimentaci√≥n
        """)

        temperature = st.slider(
            "Temperatura",
            min_value=0.1,
            max_value=0.5,
            value=config.ollama.temperature,
            step=0.05,
            help="Menor temperatura = respuestas m√°s deterministas"
        )

        # Bot√≥n guardar
        if st.button("üíæ Guardar Configuraci√≥n de IA", type="primary", use_container_width=True):
            new_config = {
                "ollama": {
                    "model": model_name,
                    "temperature": float(temperature)
                }
            }

            save_user_overrides(new_config)
            reload_config()  # Recargar config para que se vea inmediatamente
            st.success(f"‚úÖ Configuraci√≥n guardada: Modelo **{model_name}**, Temperatura **{temperature}**")
            st.info("üîÑ Reinicia la aplicaci√≥n para aplicar los cambios completamente.")

    # Tab 2: Configuraci√≥n de OCR
    with tab2:
        st.markdown("### Reconocimiento √ìptico de Caracteres (OCR)")

        st.markdown("""
        Configuraci√≥n para procesar documentos escaneados o im√°genes.
        """)

        # Idioma OCR
        current_ocr_lang = config.ocr.languages
        ocr_lang_index = next(
            (i for i, (code, _) in enumerate(OCR_LANGUAGES) if code == current_ocr_lang),
            0
        )

        selected_ocr_lang = st.selectbox(
            "Idioma de Reconocimiento",
            options=range(len(OCR_LANGUAGES)),
            format_func=lambda i: OCR_LANGUAGES[i][1],
            index=ocr_lang_index,
            help="Idioma principal del OCR (Tesseract)"
        )

        ocr_lang_code, ocr_lang_name = OCR_LANGUAGES[selected_ocr_lang]

        st.caption(
            f"üí° Aseg√∫rate de tener instalado el paquete de idioma: `tesseract-ocr-{ocr_lang_code.split('+')[0]}`"
        )

        st.markdown("---")

        # DPI (Resoluci√≥n)
        st.markdown("### Resoluci√≥n de Escaneo (DPI)")

        dpi = st.radio(
            "Calidad de OCR",
            options=[200, 300, 400, 600],
            index={200: 0, 300: 1, 400: 2, 600: 3}.get(config.ocr.dpi, 1),
            format_func=lambda x: {
                200: "üîπ R√°pido (200 DPI)",
                300: "‚ö° Balance (300 DPI) - Recomendado",
                400: "üéØ Alta Calidad (400 DPI)",
                600: "üíé M√°xima Calidad (600 DPI) - Muy Lento"
            }[x],
            help="Mayor DPI = mejor calidad pero m√°s lento"
        )

        # Estimaci√≥n de tiempo
        time_estimate = {
            200: "~15-20s por p√°gina",
            300: "~30-40s por p√°gina",
            400: "~60-80s por p√°gina",
            600: "~120-180s por p√°gina"
        }[dpi]

        st.caption(f"‚è±Ô∏è Tiempo estimado: {time_estimate}")

        # Bot√≥n guardar
        if st.button("üíæ Guardar Configuraci√≥n de OCR", type="primary", use_container_width=True):
            new_config = {
                "ocr": {
                    "languages": ocr_lang_code,
                    "dpi": dpi
                }
            }

            save_user_overrides(new_config)
            reload_config()  # Recargar config para que se vea inmediatamente
            st.success(f"‚úÖ OCR configurado: Idioma **{ocr_lang_name}**, DPI **{dpi}**")

    # Tab 3: Configuraci√≥n Avanzada
    with tab3:
        st.markdown("### Opciones Avanzadas")

        # Chunking
        st.markdown("#### Procesamiento de Documentos Largos")

        enable_chunking = st.checkbox(
            "Activar Chunking Autom√°tico",
            value=config.chunking.enabled,
            help="Divide documentos largos en partes para an√°lisis. Recomendado mantener activado."
        )

        if enable_chunking:
            chunk_size = st.number_input(
                "Tama√±o de Chunk (caracteres)",
                min_value=5000,
                max_value=25000,
                value=15000,
                step=1000,
                help="Documentos mayores a este tama√±o se dividir√°n autom√°ticamente"
            )

            st.caption(f"üìÑ Documentos > {chunk_size:,} caracteres se procesar√°n por partes")
        else:
            chunk_size = None
            st.warning("‚ö†Ô∏è Desactivar chunking puede causar errores con documentos largos (>50 p√°ginas)")

        st.markdown("---")

        # Max Tokens
        st.markdown("#### Longitud M√°xima de Respuesta")

        max_tokens = st.slider(
            "Max Tokens",
            min_value=1000,
            max_value=8000,
            value=config.ollama.max_tokens,
            step=500,
            help="Longitud m√°xima de la respuesta del LLM"
        )

        st.caption(
            "üí° Aumentar si los an√°lisis parecen cortados. "
            "Reducir para documentos simples (m√°s r√°pido)."
        )

        st.markdown("---")

        # Reintentos
        st.markdown("#### Reintentos en Errores")

        max_retries = st.number_input(
            "Reintentos M√°ximos",
            min_value=1,
            max_value=5,
            value=2,
            help="Intentos ante respuestas JSON inv√°lidas"
        )

        # Bot√≥n guardar
        if st.button("üíæ Guardar Configuraci√≥n Avanzada", type="primary", use_container_width=True):
            new_config = {
                "chunking": {
                    "enabled": enable_chunking,
                    "max_chunk_size": chunk_size if enable_chunking else 15000
                },
                "ollama": {
                    "max_tokens": max_tokens,
                    "max_retries": max_retries
                }
            }

            save_user_overrides(new_config)
            reload_config()  # Recargar config para que se vea inmediatamente
            st.success("‚úÖ Configuraci√≥n avanzada guardada")

    # Secci√≥n de informaci√≥n
    st.markdown("---")
    st.markdown("### üìö Informaci√≥n del Sistema")

    col1, col2, col3 = st.columns(3)

    with col1:
        st.metric("Versi√≥n", "1.0.0")

    with col2:
        st.metric("Configuraci√≥n", "config/user_overrides.yaml")

    with col3:
        # Bot√≥n restablecer
        if st.button("üîÑ Restablecer a Valores por Defecto", help="Elimina personalizaciones"):
            # TODO: Implementar reset
            st.warning("Funcionalidad de reset pendiente")

    st.markdown("---")
    st.caption("üí° Los cambios de configuraci√≥n se aplican al pr√≥ximo an√°lisis. "
               "Algunos cambios (modelo, temperatura) pueden requerir reiniciar la aplicaci√≥n.")


if __name__ == "__main__":
    st.set_page_config(page_title="Configuraci√≥n", page_icon="‚öôÔ∏è", layout="wide")
    render_settings_page()
