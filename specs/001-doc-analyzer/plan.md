# Implementation Plan: Analizador de Documentos Legales

**Branch**: `001-doc-analyzer` | **Date**: 2026-02-18 | **Spec**: [spec.md](./spec.md)
**Input**: Feature specification from `/specs/001-doc-analyzer/spec.md`

## Summary

Sistema de an√°lisis local de documentos legales, laborales y administrativos que extrae puntos clave mediante IA local (Ollama), procesando PDF (nativos y escaneados), DOCX e im√°genes con OCR. Presenta resultados estructurados en 8 categor√≠as (partes, fechas, importes, obligaciones, derechos, riesgos, resumen, tipo), mantiene historial persistente de duplas (documento ‚Üî an√°lisis) y exporta resultados en JSON, todo ejecut√°ndose 100% offline con privacidad garantizada.

**Technical Approach**: Aplicaci√≥n web local con Streamlit (Python 3.10+), extracci√≥n de texto mediante pdfplumber/python-docx/pytesseract (OCR 300 DPI), an√°lisis por LLM local Ollama (llama3.2:3b), validaci√≥n de schema con Pydantic, persistencia JSON (duplas.json), y pipeline con chunking para documentos largos + consolidaci√≥n inteligente de resultados.

## Technical Context

**Language/Version**: Python 3.10+
**Primary Dependencies**:
- **UI Framework**: Streamlit 1.30+ (aplicaci√≥n web local, sin servidor externo)
- **Text Extraction**:
  - `pdfplumber 0.10+` (PDF nativos con texto embebido)
  - `python-docx 1.1+` (archivos DOCX)
  - `pdf2image 1.16+` + `pytesseract 0.3.10+` (OCR para PDFs escaneados e im√°genes, render 300 DPI, lang "spa" + "spa+eng")
- **AI Local**: Ollama (servicio local HTTP, puerto 11434) con modelo `llama3.2:3b` (preferente, 2GB VRAM) | Alternativas: `phi3:mini` (1GB VRAM) o `mistral:7b` (5GB VRAM)
- **Data Validation**: Pydantic 2.5+ (schemas para Documento/An√°lisis/Dupla, validaci√≥n JSON)
- **Utilities**: `hashlib` (SHA-256 para IDs), `pillow` (mejora de im√°genes pre-OCR)

**Storage**: Archivo JSON local (`duplas.json` en directorio del proyecto) | Futura migraci√≥n a SQLite para versiones y queries complejas

**Testing**: pytest 7.4+ con fixtures para:
- Mocks de Ollama (responses JSON simulados)
- Documentos de prueba (PDF nativo, PDF escaneado, DOCX, im√°genes)
- Validaci√≥n de schemas Pydantic
- Tests de integraci√≥n end-to-end (carga ‚Üí extracci√≥n ‚Üí an√°lisis ‚Üí persistencia)

**Target Platform**:
- **OS**: Windows 10+, macOS 12+, Linux (Ubuntu 20.04+)
- **Hardware M√≠nimo**: 4GB RAM, CPU dual-core (√∫ltimos 5 a√±os), 2GB almacenamiento
- **Hardware Recomendado**: 8GB RAM, CPU quad-core, 4GB almacenamiento, GPU opcional (acelera Ollama)
- **Software Prereqs**: Tesseract OCR instalado en sistema, Ollama service ejecut√°ndose localmente

**Project Type**: Single project (aplicaci√≥n standalone Python con UI web local v√≠a Streamlit)

**Performance Goals**:
- PDF nativo (10-20 p√°ginas): an√°lisis completo en <30 segundos
- PDF escaneado (5-10 p√°ginas): OCR + an√°lisis en <60 segundos
- Procesamiento batch de 5 documentos: <5 minutos total
- Respuesta de UI (navegaci√≥n historial): <1 segundo
- Validaci√≥n JSON del LLM: >85% √©xito al primer intento

**Constraints**:
- **Privacidad absoluta**: 0% transmisi√≥n de datos fuera del equipo sin consentimiento expl√≠cito (Principio I - Constituci√≥n)
- **Veracidad obligatoria**: 100% del contenido del an√°lisis debe ser verificable contra documento fuente (Principio VI - Constituci√≥n)
- **Estructura inmutable**: 8 categor√≠as en orden fijo para todos los documentos (Regla R2 - Constituci√≥n)
- **L√≠mite de tama√±o de archivo**: 100MB m√°ximo por documento (restricci√≥n pr√°ctica de memoria)
- **Context window del LLM**: ~4000 tokens (llama3.2:3b) ‚Üí requiere chunking para docs >10 p√°ginas
- **Temperatura del LLM**: 0.1-0.3 (determinismo alto, reducir variabilidad)
- **Sin conexi√≥n internet**: Core features deben funcionar offline (Ollama local, OCR local, persistencia local)

**Scale/Scope**:
- Historial: hasta 1000 duplas (an√°lisis) almacenadas localmente
- Documentos: 1-100 p√°ginas (98% de casos), soporta hasta 500 p√°ginas con chunking
- Usuarios: single-user local (no multi-tenancy)
- Idiomas: espa√±ol (primario), ingl√©s (secundario), detecci√≥n autom√°tica de idioma

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

### ‚úÖ Principio I - Privacidad y Operaci√≥n Local

**Status**: ‚úÖ **CUMPLE**

**Validaci√≥n**:
- ‚úÖ Ollama ejecuta localmente (no Claude API, OpenAI API ni servicios cloud)
- ‚úÖ OCR via pytesseract (biblioteca local, no Google Vision API ni AWS Textract)
- ‚úÖ Extracci√≥n de texto con bibliotecas Python puras (pdfplumber, python-docx)
- ‚úÖ Almacenamiento en archivo JSON local (`duplas.json`) sin sincronizaci√≥n cloud
- ‚úÖ Streamlit en modo local (no Streamlit Cloud deployment)
- ‚úÖ Sin telemetr√≠a ni analytics externos

**Implicaciones en Arquitectura**:
- Documentar en quickstart.md c√≥mo instalar Ollama localmente
- Incluir health check en UI para verificar que Ollama est√° ejecutando en `localhost:11434`
- Mostrar badge "üîí 100% Local" en UI para reforzar confianza
- Implementar flag de configuraci√≥n para deshabilitar cualquier futura feature que requiera red

**Riesgos Mitigados**:
- No hay riesgo de filtraci√≥n de documentos sensibles a servicios externos
- Usuario mantiene control absoluto de datos en su filesystem

### ‚úÖ Principio II - Carga y Visualizaci√≥n M√∫ltiple

**Status**: ‚úÖ **CUMPLE**

**Validaci√≥n**:
- ‚úÖ Streamlit `file_uploader` con par√°metro `accept_multiple_files=True`
- ‚úÖ Pipeline procesa lista de archivos en secuencia (batch processing)
- ‚úÖ Historial lateral tipo sidebar muestra todas las duplas con metadata individual
- ‚úÖ Cada an√°lisis mantiene estructura independiente (no hay merge involuntario)

**Implementaci√≥n**:
- US3 (Carga M√∫ltiple) implementa este principio directamente
- UI con indicador de progreso: "Procesando 3 de 5 documentos..."

### ‚úÖ Principio III - Interfaz Clara y Directa

**Status**: ‚úÖ **CUMPLE**

**Validaci√≥n**:
- ‚úÖ Cada dupla en historial incluye `documento.nombre` + `analisis.tipo_documento` como t√≠tulo
- ‚úÖ Click en dupla ‚Üí recupera an√°lisis exacto sin ambig√ºedad (match por `dupla.id`)
- ‚úÖ UI muestra metadata de trazabilidad: "Analizado el 2026-02-18 14:30 | 12 p√°ginas | PDF OCR"

**Implementaci√≥n**:
- Sidebar de Streamlit con lista de duplas (st.selectbox o custom component)
- Panel principal muestra an√°lisis seleccionado con referencia expl√≠cita al documento origen

### ‚úÖ Principio IV - Resultados Estructurados

**Status**: ‚úÖ **CUMPLE**

**Validaci√≥n**:
- ‚úÖ Esquema Pydantic valida las 8 categor√≠as obligatorias
- ‚úÖ UI usa expanders/cards de Streamlit para separar visualmente cada categor√≠a
- ‚úÖ Listas con bullets (st.markdown) para obligaciones, derechos, riesgos, resumen
- ‚úÖ Fechas e importes en formato tabular (st.dataframe o st.table)

**Implementaci√≥n**:
- Template de presentaci√≥n en Streamlit con secciones colapsables
- Evitar texto plano sin formato ‚Üí usar componentes estructurados

### ‚úÖ Principio V - Independencia de Formato

**Status**: ‚úÖ **CUMPLE**

**Validaci√≥n**:
- ‚úÖ `extract_text_auto(path)` detecta formato y delega a extractor apropiado
- ‚úÖ Normalizaci√≥n de texto com√∫n post-extracci√≥n (espacios, saltos de l√≠nea)
- ‚úÖ Pipeline de an√°lisis recibe texto plano sin conocer formato origen
- ‚úÖ Metadata `documento.tipo_fuente` registra origen pero no afecta an√°lisis

**Implementaci√≥n**:
```python
def extract_text_auto(file_path: Path) -> tuple[str, int, str]:
    """Detecta formato y extrae texto normalizado"""
    if file_path.suffix.lower() == '.pdf':
        # Intenta pdfplumber ‚Üí si falla/vac√≠o, aplica OCR
    elif file_path.suffix.lower() in ['.docx', '.doc']:
        # python-docx
    elif file_path.suffix.lower() in ['.png', '.jpg', '.jpeg', '.tiff']:
        # pytesseract directo
    # Normalizaci√≥n com√∫n para todos
    return (texto, paginas, tipo_fuente)
```

### ‚úÖ Principio VI - Veracidad de la Informaci√≥n

**Status**: ‚úÖ **CUMPLE** con **Mitigaciones Cr√≠ticas**

**Validaci√≥n**:
- ‚úÖ LLM_CONSTITUTION prompt incluye: "No inventes datos. Extrae √∫nicamente informaci√≥n presente en el texto."
- ‚úÖ Validaci√≥n heur√≠stica post-an√°lisis: verificar que fechas/n√∫meros del JSON aparecen en texto fuente
- ‚úÖ Campo `analisis.confianza_aprox` refleja nivel de verificabilidad (0.0-1.0)
- ‚úÖ Campo `analisis.notas[]` documenta limitaciones expl√≠citas ("Texto escaso", "OCR de baja calidad")
- ‚úÖ Categor√≠as vac√≠as se devuelven como `[]` o `null`, no con placeholders inventados

**Mitigaciones Cr√≠ticas**:
1. **Temperatura baja (0.1-0.3)** ‚Üí reduce creatividad del LLM, aumenta reproducibilidad
2. **Reintentos con correcci√≥n** ‚Üí si JSON inv√°lido, pedir correcci√≥n sin inventar
3. **Schema estricto Pydantic** ‚Üí campos tipados, no permite free-form text que invite a especulaci√≥n
4. **Logging de prompts** ‚Üí permitir auditor√≠a de qu√© se envi√≥ al LLM vs qu√© devolvi√≥

**Riesgos Residuales**:
- **Riesgo**: LLM local puede alucinar nombres de entidades similares pero no exactos
  - **Mitigaci√≥n**: Validaci√≥n fuzzy string matching: si `partes[0]` no aparece literal en texto, bajar `confianza_aprox` y a√±adir nota
- **Riesgo**: Interpretaci√≥n de importes ambiguos ("hasta 5000‚Ç¨" ‚Üí ¬ø5000 o rango?)
  - **Mitigaci√≥n**: Preferir literals cuando hay ambig√ºedad, usar `notas` para aclarar contexto

**Testing**:
- Test case con documento inventado ‚Üí verificar que an√°lisis no a√±ade informaci√≥n ausente
- Test case con documento ambiguo ‚Üí verificar que `notas` reconoce limitaci√≥n

### ‚úÖ Principio VII - Historial y Gesti√≥n

**Status**: ‚úÖ **CUMPLE**

**Validaci√≥n**:
- ‚úÖ `duplas.json` persiste tras cada an√°lisis exitoso
- ‚úÖ UI sidebar muestra lista completa de duplas con ordenamiento configurable
- ‚úÖ Operaci√≥n de eliminaci√≥n con confirmaci√≥n (st.button + st.warning)
- ‚úÖ Exportaci√≥n de historial completo (JSON) para backup

**Implementaci√≥n**:
- US2 (Historial de Duplas) implementa este principio directamente
- CRUD operations: Create (an√°lisis nuevo), Read (seleccionar dupla), Delete (con confirmaci√≥n)
- Futura extensi√≥n: filtrado por tipo de documento, b√∫squeda por partes/fechas

### ‚úÖ Principio VIII - Experiencia del Usuario

**Status**: ‚úÖ **CUMPLE**

**Validaci√≥n**:
- ‚úÖ Flujo de 3 pasos: (1) Cargar documento(s) ‚Üí (2) Ver an√°lisis ‚Üí (3) Gestionar historial
- ‚úÖ Streamlit proporciona UI intuitiva sin terminolog√≠a t√©cnica ("Cargar Documento" no "Upload File to Buffer")
- ‚úÖ Defaults razonables: OCR a 300 DPI (no requiere configuraci√≥n), idioma espa√±ol por defecto
- ‚úÖ Indicadores de progreso con mensajes claros: "Extrayendo texto..." no "Parsing PDF stream objects"

**Anti-patterns Evitados**:
- ‚ùå No mostrar logs t√©cnicos en UI (JSON raw, stack traces ‚Üí solo en console/logs)
- ‚ùå No requerir configuraci√≥n de Ollama model path (auto-detect localhost:11434)
- ‚ùå No pedir al usuario elegir entre "pdfplumber vs pymupdf" (auto-detect mejor opci√≥n)

**Implementaci√≥n**:
- Streamlit config (`config.toml`) con tema limpio y profesional
- Mensajes de error user-friendly: "No se pudo leer el archivo PDF. Verifica que no est√© protegido con contrase√±a." en lugar de "PyPDF2.errors.PdfReadError: EOF marker not found"

### ‚úÖ Principio IX - Extensibilidad

**Status**: ‚úÖ **CUMPLE**

**Validaci√≥n**:
- ‚úÖ Arquitectura en capas (UI, Extracci√≥n, Orquestaci√≥n, Datos) permite reemplazar componentes
- ‚úÖ Futuro soporte de nuevos formatos (RTF, TXT) requiere solo a√±adir handler en `extract_text_auto`
- ‚úÖ Migraci√≥n a SQLite planificada sin romper `duplas.json` existente (read-compatibility)
- ‚úÖ Nuevas categor√≠as de an√°lisis requieren solo actualizar schema Pydantic + prompt LLM

**Extensiones Futuras Compatibles**:
- A√±adir an√°lisis comparativo (diff entre 2 duplas) sin afectar an√°lisis individual
- Integraci√≥n con servicios opcionales de traducci√≥n (opt-in, no obligatorio)
- Plugin system para extractores custom (ej: SAP PDFs con formato propietario)

**Constraints para Extensiones**:
- Toda extensi√≥n DEBE pasar Constitution Check (re-validar Principio I Privacidad)
- Nuevas features DEBEN ser opt-in si introducen dependencias externas

---

### ‚ö†Ô∏è  Constitutional Compliance Summary

**Overall Status**: ‚úÖ **TODOS LOS PRINCIPIOS CUMPLIDOS**

**Violations**: 0 (cero violaciones)

**Justifications Required**: N/A

**Re-Check After Phase 1**: ‚úÖ Mandatory (verificar que data-model.md y contracts/ mantienen alineaci√≥n)

## Project Structure

### Documentation (this feature)

```text
specs/001-doc-analyzer/
‚îú‚îÄ‚îÄ spec.md              # Feature specification (completed)
‚îú‚îÄ‚îÄ plan.md              # This file (implementation plan)
‚îú‚îÄ‚îÄ research.md          # Phase 0: Technology research & decisions
‚îú‚îÄ‚îÄ data-model.md        # Phase 1: Entidades Documento/An√°lisis/Dupla
‚îú‚îÄ‚îÄ quickstart.md        # Phase 1: Gu√≠a de instalaci√≥n y primeros pasos
‚îú‚îÄ‚îÄ contracts/           # Phase 1: Schemas (Pydantic models, JSON examples)
‚îÇ   ‚îú‚îÄ‚îÄ documento.schema.json
‚îÇ   ‚îú‚îÄ‚îÄ analisis.schema.json
‚îÇ   ‚îú‚îÄ‚îÄ dupla.schema.json
‚îÇ   ‚îî‚îÄ‚îÄ ollama-prompt.md
‚îú‚îÄ‚îÄ checklists/
‚îÇ   ‚îî‚îÄ‚îÄ requirements.md  # Spec validation (completed)
‚îî‚îÄ‚îÄ tasks.md             # Phase 2: Task list (generated by /speckit.tasks)
```

### Source Code (repository root)

```text
# Single Project Structure (Python)
src/
‚îú‚îÄ‚îÄ models/                      # Entidades y schemas Pydantic
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ documento.py             # Clase Documento + schema
‚îÇ   ‚îú‚îÄ‚îÄ analisis.py              # Clase Analisis + schema
‚îÇ   ‚îî‚îÄ‚îÄ dupla.py                 # Clase Dupla + schema
‚îú‚îÄ‚îÄ extractors/                  # Capa de extracci√≥n de texto
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ base.py                  # Abstract BaseExtractor
‚îÇ   ‚îú‚îÄ‚îÄ pdf_native.py            # pdfplumber para PDFs nativos
‚îÇ   ‚îú‚îÄ‚îÄ pdf_ocr.py               # pdf2image + pytesseract para escaneados
‚îÇ   ‚îú‚îÄ‚îÄ docx_extractor.py        # python-docx para DOCX
‚îÇ   ‚îî‚îÄ‚îÄ image_extractor.py       # pytesseract directo para im√°genes
‚îú‚îÄ‚îÄ orchestration/               # Capa de orquestaci√≥n de an√°lisis
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ analyzer.py              # Pipeline principal: extracci√≥n ‚Üí an√°lisis ‚Üí validaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ ollama_client.py         # Cliente HTTP para Ollama API
‚îÇ   ‚îú‚îÄ‚îÄ prompt_builder.py        # Ensambla prompts (Constitution + Specify + Plan + Texto)
‚îÇ   ‚îú‚îÄ‚îÄ json_validator.py        # Validaci√≥n de JSON contra schemas, reintentos
‚îÇ   ‚îî‚îÄ‚îÄ chunker.py               # Chunking para documentos largos + consolidaci√≥n
‚îú‚îÄ‚îÄ persistence/                 # Capa de datos y almacenamiento
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ json_store.py            # CRUD operations sobre duplas.json
‚îÇ   ‚îî‚îÄ‚îÄ sqlite_store.py          # (Futuro) Migraci√≥n a SQLite
‚îú‚îÄ‚îÄ ui/                          # Capa de interfaz Streamlit
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ app.py                   # Entry point de Streamlit (st.run)
‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ file_uploader.py     # Componente de carga m√∫ltiple
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ analysis_view.py     # Tarjetas/bullets por categor√≠as
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ history_sidebar.py   # Lista de duplas en sidebar
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ export_buttons.py    # Controles de exportaci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ pages/                   # (Opcional) Multi-page app
‚îÇ       ‚îú‚îÄ‚îÄ main.py              # P√°gina principal
‚îÇ       ‚îî‚îÄ‚îÄ settings.py          # Configuraci√≥n (OCR DPI, modelo Ollama)
‚îî‚îÄ‚îÄ utils/                       # Utilidades transversales
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ hashing.py               # SHA-256 para IDs de documento
    ‚îú‚îÄ‚îÄ logging_config.py        # Setup de logging
    ‚îú‚îÄ‚îÄ text_normalizer.py       # Normalizaci√≥n de texto post-extracci√≥n
    ‚îî‚îÄ‚îÄ validators.py            # Validaciones heur√≠sticas (fechas, importes)

tests/
‚îú‚îÄ‚îÄ unit/                        # Tests de unidad por m√≥dulo
‚îÇ   ‚îú‚îÄ‚îÄ test_extractors.py      # Mock PDFs/DOCX/im√°genes
‚îÇ   ‚îú‚îÄ‚îÄ test_analyzer.py         # Mock Ollama responses
‚îÇ   ‚îú‚îÄ‚îÄ test_json_validator.py   # Casos de JSONs v√°lidos/inv√°lidos
‚îÇ   ‚îî‚îÄ‚îÄ test_chunker.py          # Tests de chunking + consolidaci√≥n
‚îú‚îÄ‚îÄ integration/                 # Tests end-to-end
‚îÇ   ‚îú‚îÄ‚îÄ test_pipeline.py         # Carga ‚Üí Extracci√≥n ‚Üí An√°lisis ‚Üí Persistencia
‚îÇ   ‚îî‚îÄ‚îÄ test_ui.py               # (Opcional) Selenium/Playwright para UI
‚îú‚îÄ‚îÄ fixtures/                    # Documentos de prueba
‚îÇ   ‚îú‚îÄ‚îÄ contrato_laboral.pdf     # PDF nativo (10 p√°ginas)
‚îÇ   ‚îú‚îÄ‚îÄ nomina_escaneada.pdf     # PDF escaneado (2 p√°ginas)
‚îÇ   ‚îú‚îÄ‚îÄ convenio.docx            # DOCX (5 p√°ginas)
‚îÇ   ‚îî‚îÄ‚îÄ recibo_imagen.png        # Imagen de recibo
‚îî‚îÄ‚îÄ conftest.py                  # Fixtures de pytest (mocks Ollama, temp dirs)

data/                            # Almacenamiento local de datos
‚îú‚îÄ‚îÄ duplas.json                  # Historial de an√°lisis (MVP)
‚îú‚îÄ‚îÄ uploads/                     # Temporal para archivos cargados
‚îî‚îÄ‚îÄ cache/                       # (Opcional) Cache de OCR para re-procesamiento r√°pido

config/                          # Configuraci√≥n de aplicaci√≥n
‚îú‚îÄ‚îÄ ollama_config.yaml           # Endpoints, modelos, temperatura
‚îú‚îÄ‚îÄ streamlit_config.toml        # Tema y configuraci√≥n de Streamlit
‚îî‚îÄ‚îÄ logging.yaml                 # Niveles de log por m√≥dulo

docs/                            # Documentaci√≥n t√©cnica adicional
‚îú‚îÄ‚îÄ architecture.md              # Diagrama de capas y flujo de datos
‚îú‚îÄ‚îÄ prompts.md                   # Documentaci√≥n detallada de prompts del LLM
‚îî‚îÄ‚îÄ deployment.md                # Gu√≠a de instalaci√≥n de prereqs (Ollama, Tesseract)

requirements.txt                 # Dependencias Python (pip)
pyproject.toml                   # Configuraci√≥n de proyecto (Poetry/PDM opcional)
.gitignore                       # Excluir data/, uploads/, cache/
README.md                        # Overview del proyecto y quickstart
```

**Structure Decision**:
Seleccionada **Opci√≥n 1 - Single Project** porque:
- No hay frontend/backend separados (Streamlit embebe UI en mismo proceso Python)
- No hay API REST externa (Ollama es dependency local, no servicio propio)
- Arquitectura monol√≠tica simplifica deployment (un solo comando `streamlit run`)
- Capas l√≥gicas separadas en directorios (`models/`, `extractors/`, `orchestration/`, `ui/`) mantienen modularidad sin overhead de microservicios

Estructura permite migraci√≥n futura a arquitectura web (FastAPI backend + React frontend) si se requiere multi-usuario o deployment cloud, pero MVP prioriza simplicidad de single-user local.

## Complexity Tracking

> **Fill ONLY if Constitution Check has violations that must be justified**

**N/A** - No hay violaciones constitucionales que requieran justificaci√≥n.

Todas las decisiones t√©cnicas (Ollama local, pytesseract, JSON storage, Streamlit local) est√°n alineadas con los 9 principios inmutables de la constituci√≥n, especialmente Principio I (Privacidad Local) y Principio VI (Veracidad de la Informaci√≥n).

---

## Phase 0: Research & Decisions

*Output: `research.md` documenting technology choices and rationale*

**Research Completed**: ‚úÖ (decisions provided by user, documented below)

### Decision 1: Language & Framework - Python 3.10+ con Streamlit

**Rationale**:
- **Python**: Ecosistema maduro para ML/NLP (Ollama Python SDK), procesamiento de documentos (pdfplumber, python-docx), OCR (pytesseract bindings)
- **Streamlit**: Framework r√°pido para prototipos de ML apps, requiere m√≠nimo c√≥digo para UI compleja, soporta components interactivos (file uploader, sidebar, expanders), deployment local trivial (`streamlit run app.py`)
- **Alternativas consideradas**:
  - Flask/FastAPI + HTML/JS: Mayor control pero 3-5x m√°s c√≥digo, overhead innecesario para single-user local
  - Jupyter Notebook: No apto para end-users no t√©cnicos, falta UI production-ready
  - Electron + Python: Complejidad de empaquetado, overhead de Chromium

**Best Practices**:
- Usar virtual environments (venv/conda) para aislar dependencias
- Pin versions en requirements.txt para reproducibilidad
- Streamlit session_state para persistencia de estado entre reruns

### Decision 2: Text Extraction - pdfplumber + python-docx + pytesseract

**Rationale**:
- **pdfplumber** (PDFs nativos): Mejor balance extracci√≥n/layout, soporta tablas, open-source
  - Alternativas: PyPDF2 (b√°sico), pymupdf (r√°pido pero licencia AGPL), pdfminer (complejo)
- **python-docx** (DOCX): Est√°ndar de facto, soporta estilos y tablas, activamente mantenido
  - Alternativas: docx2txt (solo texto plano, pierde estructura)
- **pytesseract + pdf2image** (OCR):
  - Tesseract: Open-source maduro (Google), soporta 100+ idiomas incluido espa√±ol, detecci√≥n autom√°tica de layout
  - pdf2image: Convierte PDF pages a im√°genes para OCR (usa poppler internamente)
  - **300 DPI**: Balance calidad/velocidad (200 DPI = r√°pido pero inexacto, 400 DPI = lento pero preciso)
  - **"spa" + "spa+eng"**: Espa√±ol primario, fallback a multilenguaje para documentos h√≠bridos
  - Alternativas cloud descartadas: Google Vision API (viola Principio I), AWS Textract (pago + cloud)

**Best Practices**:
- Pre-procesamiento de im√°genes: binarizaci√≥n, deskew, noise reduction (Pillow)
- Detecci√≥n autom√°tica de texto en PDF antes de OCR (evitar OCR innecesario)
- Chunking de PDFs grandes: 1 p√°gina a la vez para OCR (gesti√≥n de memoria)

### Decision 3: LLM Local - Ollama con llama3.2:3b

**Rationale**:
- **Ollama**: Servicio local HTTP que gestiona modelos LLM, f√°cil instalaci√≥n (single binary), API REST simple, soporta streaming, GPU acceleration opcional
  - Alternativas: llama.cpp (m√°s control pero requiere compilaci√≥n), Hugging Face Transformers (complejo, overhead de dependencies)
- **llama3.2:3b**:
  - **Pros**: Equilibrio calidad/recursos (2GB VRAM), buen seguimiento de instrucciones JSON, context window 4K tokens, inference ~2-5 sec/respuesta en CPU
  - **Cons**: Puede alucinar con documentos ambiguos (mitigar con temperatura baja + validaci√≥n)
- **Alternativas**:
  - **phi3:mini** (1GB): M√°s ligero, bueno para HW limitado, menor calidad de extracci√≥n de entidades complejas
  - **mistral:7b** (5GB): Mejor calidad, requiere 8GB+ RAM, inference m√°s lenta (5-10 sec)
  - **GPT-4/Claude API**: Descartados por violar Principio I (cloud) y costo por uso

**Best Practices**:
- Temperatura 0.1-0.3 para tareas de extracci√≥n (reduce creatividad)
- System prompt robusto con ejemplos few-shot (mejora adherencia a schema JSON)
- Timeouts generosos (30-60 seg) para inference en CPU
- Reintentos con backoff exponencial si Ollama no responde

### Decision 4: Data Validation - Pydantic 2.5+

**Rationale**:
- **Pydantic**: Validaci√≥n de schemas Python con typing nativo, serializaci√≥n/deserializaci√≥n JSON autom√°tica, mensajes de error claros
  - Alternativas: marshmallow (menos type-safe), dataclasses + manual validation (m√°s c√≥digo)
- **Use cases**:
  - Definir schemas de Documento/An√°lisis/Dupla con tipos estrictos
  - Validar JSON del LLM contra schema antes de persistir
  - Auto-generar JSON Schema para documentaci√≥n (contracts/)

**Best Practices**:
- Usar `Field(..., description="...")` para documentar campos
- Validators custom para l√≥gica compleja (ej: verificar que fechas est√°n en formato ISO o literal)
- Strict mode para rechazar campos extra del LLM

### Decision 5: Persistence - JSON file (duplas.json) ‚Üí SQLite (fase 2)

**Rationale**:
- **MVP (JSON file)**:
  - **Pros**: Zero setup, human-readable, f√°cil backup (copy file), compatible con git
  - **Cons**: Performance degrada con >1000 duplas, no soporta queries complejas, riesgo de corrupci√≥n con escrituras concurrentes
  - **Uso**: Historial lineal, CRUD simple, exportaci√≥n directa
- **Fase 2 (SQLite)**:
  - **Pros**: Queries r√°pidas (filtrar por tipo_documento, fechas), transacciones ACID, soporta versiones de an√°lisis, schema migrations
  - **Cons**: Requiere schema design, m√°s complejo de debug
  - **Migraci√≥n**: Script de import de duplas.json ‚Üí SQLite (preservar backward compatibility)

**Best Practices**:
- JSON: atomic writes (write to temp file ‚Üí rename), validation antes de guardar
- SQLite: usar ORM ligero (SQLModel = Pydantic + SQLAlchemy) para mantener consistency con schemas Pydantic

### Decision 6: Chunking Strategy - Sliding window con consolidaci√≥n inteligente

**Rationale**:
- **Problema**: llama3.2:3b tiene context window de ~4K tokens (~3000 palabras). Documentos de 20+ p√°ginas exceden l√≠mite.
- **Soluci√≥n**:
  1. **Chunking**: Dividir texto en chunks de ~2500 palabras con overlap de 200 palabras (preserva contexto en fronteras)
  2. **An√°lisis por chunk**: Cada chunk genera JSON parcial
  3. **Consolidaci√≥n**: Merge de listas (partes, fechas, obligaciones), deduplicaci√≥n fuzzy (similaridad >90%), reconciliaci√≥n de conflictos (conservar todos los valores + nota en `analisis.notas`)
  4. **Recorte final**: `resumen_bullets` limitado a 10 items (priorizar bullets m√°s densos en keywords)

**Alternativas consideradas**:
- Map-Reduce: Chunk ‚Üí summarize ‚Üí re-analyze summaries (pierde detalles, 2 pasadas de LLM)
- Embeddings + RAG: Over-engineering para MVP, requiere vector DB

**Best Practices**:
- Chunking respeta fronteras de p√°rrafos (no cortar frases)
- Deduplicaci√≥n de fechas/importes por valor exacto
- Consolidaci√≥n de partes por similitud de nombres (Levenshtein distance)

---

*See [research.md](./research.md) for detailed investigation and trade-offs*

## Phase 1: Design & Contracts

*Output: `data-model.md`, `/contracts/*.schema.json`, `quickstart.md`*

### Data Model Summary

**Core Entities** (see [data-model.md](./data-model.md) for full schemas):

1. **Documento** (archivo cargado):
   - `id: str` (SHA-256 truncado a 16 chars)
   - `nombre: str` (filename original)
   - `tipo_fuente: Literal["pdf_native", "pdf_ocr", "docx", "image", "txt"]`
   - `paginas: int | None`, `bytes: int`, `idioma_detectado: str | None`
   - `ts_ingesta: datetime`

2. **An√°lisis** (resultado del LLM):
   - `tipo_documento: str` (contrato_laboral | convenio | nomina | desconocido)
   - `partes: list[str]` (entidades/denominaciones)
   - `fechas: list[Fecha]` donde `Fecha = {etiqueta: str, valor: str}`
   - `importes: list[Importe]` donde `Importe = {concepto: str, valor: float | None, moneda: str | None}`
   - `obligaciones: list[str]`, `derechos: list[str]`, `riesgos: list[str]`
   - `resumen_bullets: list[str]` (5-10 items)
   - `notas: list[str]` (advertencias, limitaciones)
   - `confianza_aprox: float` (0.0-1.0, heur√≠stica de verificabilidad)

3. **Dupla** (asociaci√≥n persistente):
   - `id: str` (mismo que `documento.id`)
   - `documento: Documento`
   - `analisis: Analisis`
   - `ts_creacion: datetime`, `ts_actualizacion: datetime`
   - `estado: Literal["valido", "incompleto", "con_advertencias"]`

**Relationships**:
- Dupla 1:1 Documento (una dupla por documento por ejecuci√≥n)
- Dupla 1:1 An√°lisis (un an√°lisis por dupla)
- Historial 1:N Duplas (lista de duplas ordenadas cronol√≥gicamente)

### Contract Artifacts

**Files in `/contracts/`** (see [contracts/](./contracts/) directory):

1. `documento.schema.json` - JSON Schema de Documento (Pydantic model export)
2. `analisis.schema.json` - JSON Schema de An√°lisis (validaci√≥n de response del LLM)
3. `dupla.schema.json` - JSON Schema de Dupla completa
4. `ollama-prompt.md` - Documentaci√≥n de prompts (Constitution, Specify, Plan) con ejemplos
5. `example-request.json` - Request HTTP a Ollama (POST /api/generate)
6. `example-response.json` - Response v√°lido del LLM con an√°lisis completo

**API Contract - Ollama HTTP**:
```
Endpoint: POST http://localhost:11434/api/generate
Headers: {"Content-Type": "application/json"}
Body: {
  "model": "llama3.2:3b",
  "prompt": "{CONSTITUTION + SPECIFY + PLAN + DOCUMENTO}",
  "temperature": 0.2,
  "stream": false,
  "format": "json"
}
Response: {
  "response": "{json_string_con_analisis}",
  "done": true
}
```

### Quickstart Guide

**User-facing quick-start** (see [quickstart.md](./quickstart.md)):

1. **Prerrequisitos**:
   - Python 3.10+ instalado
   - Tesseract OCR instalado (`brew install tesseract` macOS, `apt install tesseract-ocr` Linux, [installer](https://github.com/UB-Mannheim/tesseract/wiki) Windows)
   - Ollama instalado y ejecutando ([ollama.com](https://ollama.com))

2. **Instalaci√≥n**:
   ```bash
   git clone <repo>
   cd <repo>
   python -m venv venv
   source venv/bin/activate  # Windows: venv\Scripts\activate
   pip install -r requirements.txt
   ollama pull llama3.2:3b
   ```

3. **Ejecuci√≥n**:
   ```bash
   streamlit run src/ui/app.py
   ```
   Abre navegador en http://localhost:8501

4. **Uso b√°sico**:
   - Cargar documento(s) con bot√≥n "Seleccionar archivos"
   - Esperar an√°lisis (indicador de progreso)
   - Ver resultados en tarjetas por categor√≠a
   - Navegar historial en barra lateral
   - Exportar con bot√≥n "Exportar JSON"

---

### Agent Context Update

**Action**: Run `.specify/scripts/powershell/update-agent-context.ps1 -AgentType claude`

**Expected Changes**:
- Add Python 3.10+, Streamlit, Ollama to technology stack
- Add pdfplumber, python-docx, pytesseract to dependencies
- Preserve manual additions between markers

*Note: This step will be executed automatically at end of Phase 1*

---

## Constitutional Re-Check (Post-Design)

*GATE: Verify all design decisions maintain constitutional compliance*

### Re-validation Results

‚úÖ **Principio I (Privacidad)**: Data model no incluye campos de sincronizaci√≥n cloud, schemas no requieren tokens de API externa

‚úÖ **Principio VI (Veracidad)**: Campo `confianza_aprox` + `notas[]` permite transparencia sobre limitaciones, schema no permite campos ambiguos

‚úÖ **Regla R2 (8 categor√≠as)**: Schema `Analisis` define exactamente las 8 categor√≠as obligatorias como campos requeridos

‚úÖ **Regla R5 (Estructura inmutable)**: Schema Pydantic con `frozen=True` previene modificaci√≥n post-creaci√≥n

**Status**: ‚úÖ **ALL GATES PASSED** - Proceed to Phase 2 (Task Generation)

---

## Next Steps

1. ‚úÖ **Phase 0 & 1 Complete**: research.md, data-model.md, contracts/, quickstart.md generated
2. ‚è≠Ô∏è  **Phase 2**: Run `/speckit.tasks` to generate dependency-ordered task list (tasks.md)
3. ‚è≠Ô∏è  **Phase 3**: Run `/speckit.implement` to execute tasks with validation

**Artifacts Ready for Development**:
- [spec.md](./spec.md) - Business requirements (WHAT & WHY)
- [plan.md](./plan.md) - Technical implementation (HOW)
- [research.md](./research.md) - Technology decisions & rationale
- [data-model.md](./data-model.md) - Entity schemas & relationships
- [contracts/](./contracts/) - API schemas & examples
- [quickstart.md](./quickstart.md) - Installation & usage guide

**Estimated Development Time**: 6-7 days (see Hitos H1-H4 in user input)

**Ready to proceed with `/speckit.tasks`** ‚úÖ
